---
title: "Analisis exploratorio de la base de Properati"
---

```{r echo=FALSE, output = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(dplyr)
library(plotly)

data <- read_csv("../data/ar_properties.csv")
```

Filtro de los datos

```{r}
data <- data %>% 
                   # Me quedo con los que pertenecen a Argentina, Capital Federal y Boedo
            filter(l1 == "Argentina", 
                   l2 == "Capital Federal",
                   l3=="Boedo",
                   # cuyo precio este en dolares 
                   currency == "USD", 
                   # propiedad tipo Casa
                   property_type %in% c("Casa"),
                   # operaciones de venta
                   operation_type == "Venta") %>% 
            dplyr::select(id, l3, surface_total, surface_covered, price) %>% mutate(Precio=price,Sup=surface_covered,Fondo=surface_total-surface_covered) %>% dplyr::select(Sup,Fondo,Precio) %>%  filter(Fondo>=0) %>% na.omit()
```

```{r}
head(data) 
```

# Planteo del modelo

$$
h_0 = \mu + \alpha * Sup
$$\

```{r}
# Normalización de los datos
x <- scale(data$Sup, center = TRUE, scale = TRUE)
y <- scale(data$Precio, center = TRUE, scale = TRUE)
n <- length(y)  # Número de observaciones
```

```{r}
gradient_descent <- function(x, y, mu, iterations) {
  m <- 0  # Pendiente inicial
  b <- 0  # Intercepto inicial
  n <- length(y)
  
  cost_history <- numeric(iterations)
  m_history <- numeric(iterations)
  b_history <- numeric(iterations)
  
  for (i in 1:iterations) {
    y_pred <- m * x + b
    error <- y_pred - y
    cost <- sum(error^2) / (2 * n)
    
    # Almacenamos el historial
    cost_history[i] <- cost
    m_history[i] <- m
    b_history[i] <- b
    
    # Calculamos los gradientes
    dm <- (1 / n) * sum(error * x)
    db <- (1 / n) * sum(error)
    
    # Actualizamos los parámetros
    m <- m - mu * dm
    b <- b - mu * db
  }
  
  return(list(m = m, b = b, cost_history = cost_history, m_history = m_history, b_history = b_history, mu = mu))
}

```

```{r}
options(scipen=999)
```

```{r}
# Parámetros
mu <- 0.01  # Tasa de aprendizaje (μ)
iterations <- 1000

# Ejecutamos el descenso por gradiente
result <- gradient_descent(x, y, mu, iterations)

# Costo final y parámetros
final_cost <- result$cost_history[iterations]
cat("Costo final:", final_cost, "\n")
cat("Tasa de aprendizaje (μ):", result$mu, "\n")
cat("Pendiente final (m):", result$m, "\n")
cat("Intercepto final (b):", result$b, "\n")
```

```{r}
library(plotly)

# Gráfico interactivo del costo
fig_cost <- plot_ly(x = 1:iterations, y = result$cost_history, type = 'scatter', mode = 'lines') %>%
  layout(title = paste('Convergencia del Costo (μ =', mu, ')'),
         xaxis = list(title = 'Iteración'),
         yaxis = list(title = 'Costo'))

fig_cost
```

```{r}
# Predicciones finales
y_pred_final <- result$m * x + result$b

# Gráfico de dispersión con la recta ajustada
fig_regression <- plot_ly() %>%
  add_trace(x = data$Sup, y = data$Precio, type = 'scatter', mode = 'markers', name = 'Datos') %>%
  add_trace(x = data$Sup, y = y_pred_final * sd(data$Precio) + mean(data$Precio), type = 'scatter', mode = 'lines', name = 'Modelo') %>%
  layout(title = 'Ajuste del Modelo de Regresión Lineal',
         xaxis = list(title = 'Superficie'),
         yaxis = list(title = 'Precio'))

fig_regression

```

```{r}
mus <- c(0.001, 0.005, 0.01, 0.05)
cost_histories <- list()

for (mu_value in mus) {
  result_mu <- gradient_descent(x, y, mu_value, iterations)
  cost_histories[[as.character(mu_value)]] <- result_mu$cost_history
}

# Preparar datos para Plotly
df_mu <- data.frame(
  Iteration = rep(1:iterations, times = length(mus)),
  Cost = unlist(cost_histories),
  Mu = rep(mus, each = iterations)
)

# Gráfico interactivo comparando diferentes mu
fig_mu <- plot_ly(df_mu, x = ~Iteration, y = ~Cost, color = ~as.factor(Mu), type = 'scatter', mode = 'lines') %>%
  layout(title = 'Efecto de Diferentes Tasas de Aprendizaje en la Convergencia',
         xaxis = list(title = 'Iteración'),
         yaxis = list(title = 'Costo'),
         legend = list(title = list(text = 'Mu')))

fig_mu

```

```{r}
library(shiny)
library(plotly)

ui <- fluidPage(
  titlePanel("Descenso por Gradiente Interactivo"),
  
  sidebarLayout(
    sidebarPanel(
      sliderInput("mu", "Tasa de Aprendizaje (μ):", min = 0.001, max = 0.1, value = 0.01, step = 0.001),
      sliderInput("iterations", "Número de Iteraciones:", min = 100, max = 5000, value = 1000, step = 100),
      verbatimTextOutput("finalCost")
    ),
    
    mainPanel(
      plotlyOutput("costPlot"),
      plotlyOutput("regressionPlot")
    )
  )
)

server <- function(input, output) {
  
  result <- reactive({
    gradient_descent(x, y, input$mu, input$iterations)
  })
  
  output$finalCost <- renderText({
    paste("Costo final:", round(result()$cost_history[input$iterations], 4),
          "\nTasa de aprendizaje (μ):", input$mu,
          "\nPendiente final (m):", round(result()$m, 4),
          "\nIntercepto final (b):", round(result()$b, 4))
  })
  
  output$costPlot <- renderPlotly({
    df <- data.frame(
      Iteration = 1:input$iterations,
      Cost = result()$cost_history
    )
    plot_ly(df, x = ~Iteration, y = ~Cost, type = 'scatter', mode = 'lines') %>%
      layout(title = 'Convergencia del Costo',
             xaxis = list(title = 'Iteración'),
             yaxis = list(title = 'Costo'))
  })
  
  output$regressionPlot <- renderPlotly({
    y_pred <- result()$m * x + result()$b
    plot_ly() %>%
      add_trace(x = data$Sup, y = data$Precio, type = 'scatter', mode = 'markers', name = 'Datos') %>%
      add_trace(x = data$Sup, y = y_pred * sd(data$Precio) + mean(data$Precio), type = 'scatter', mode = 'lines', name = 'Modelo') %>%
      layout(title = 'Ajuste del Modelo de Regresión Lineal',
             xaxis = list(title = 'Superficie'),
             yaxis = list(title = 'Precio'))
  })
  
}

# Ejecutar la aplicación Shiny
shinyApp(ui = ui, server = server)

```

# ))))))))))))))))))))))))))))))))))))))))))))))))))))

```{r}
pf_Pi = c(8,4,4,8,8,13,4,2,5,7,2,4,1,2,4,2,1,3,5,8)
# pt_Pi = c(4,12,12,4,6,3,12,18,10,6,25,12,25,18,12,18,25,15,10,4)
```

```{r}
pf_Pi[pf_Pi <= 3]

length(pf_Pi)
```

```{r}
1 - pnorm(-0.45643)
```

```{r}
qnorm(0.95)
```

```{r}
# Datos
p_0 <- 0.4
p_hat <- 0.35
n <- 20
alpha <- 0.05 # Nivel de significancia

# Estadístico z
z <- (p_hat - p_0) / sqrt(p_0 * (1 - p_0) / n)

# Valor crítico
z_crit <- qnorm(1 - alpha)

# p-valor
p_valor <- 2 * (1 - pnorm(abs(z)))

list(z = z, z_crit = z_crit, p_valor = p_valor)
```

```{r}
ti = c( 36.604 , 25.208 , 24.418 , 24.877, 35.729 , 24.778 , 24.069 , 25.951 , 24.516 , 25.450 ,
 25.087 , 29.980 , 26.420 , 24.205 , 24.988 , 24.474 , 24.724 , 24.786 , 24.681 , 25.064)

```

```{r}
# Parámetros
n <- length(ti)               # Tamaño de la muestra
S2 <- var(ti)                 # Varianza muestral
alpha <- 0.05                    # Nivel de significancia para un IC del 95%

# Valores críticos de Chi-cuadrado
chi2_lower <- qchisq(1 - alpha / 2, df = n - 1)
chi2_upper <- qchisq(alpha / 2, df = n - 1)

# Cálculo del intervalo de confianza para la varianza
lower <- (n - 1) * S2 / chi2_lower
upper <- (n - 1) * S2 / chi2_upper

c(lower, upper) 
```

```{r}
c(sqrt(lower), sqrt(upper))
```

```{r}
# Datos
mu_0 <- 28
s <- sd(ti)

x_bar <- mean(ti)
alpha <- 0.05 # Nivel de significancia

# Estadístico t
t <- (x_bar - mu_0) / (s / sqrt(n))

# Grados de libertad
df <- n - 1

# Valor crítico
t_crit <- qt(1 - alpha, df)

# p-valor
p_valor <- (1 - pt(abs(t), df))

list(t = t, t_crit = t_crit, p_valor = p_valor)

```

```{r}
# Datos
mu_0 <- 28
s <- sd(ti)

x_bar <- mean(ti)
alpha <- 0.05 # Nivel de significancia

# Estadístico t
t <- (x_bar - mu_0) / (s / sqrt(n))

# Grados de libertad
df <- n - 1

# Valor crítico
t_crit <- qt(1 - alpha, df)

# p-valor
p_valor <- 2 * (1 - pt(abs(t), df))

list(t = t, t_crit = t_crit, p_valor = p_valor)

```

```{r}
ti=c(36.604,25.208,24.418,24.877,35.729,24.778,24.069,25.951,24.516,25.450,
     25.087,29.980,26.420,24.205,24.988,24.474,24.724,24.786,24.681,25.064) 

n4 = length(ti)
t_media = mean(ti)
t_desvio= sd(ti)

mu = 28
tobs = (t_media - mu)/(t_desvio/n4^0.5)
R4bi_pvalor = pt(tobs,n4-1)

mu = 25
tobs = (t_media - mu)/(t_desvio/n4^0.5)
R4bii_pvalor = 1-pt(tobs,n4-1)
```

```{r}
pnorm(5000,5500,37.8153, lower.tail = F)


qnorm(0.99)
```

```{r}
# Definir la ecuación
solve_equation <- function(M) {
  (420 - 70 * M) / (sqrt(M) * 10) - 2.32
}

# Resolver la ecuación usando un método numérico
library(rootSolve)
solution <- uniroot(solve_equation, lower = 0.01, upper = 100) # Rango para M
solution$root

```

```{r}
library(rootSolve)

  # Definir la ecuación
solve_equation <- function(M) {
  (420 - 70 * M) / (sqrt(M) * 10) - 2.32
}

# Resolver la ecuación usando un método numérico
solution <- uniroot(solve_equation, lower = 0.01, upper = 100) # Rango para M
solution
```

```{r}
1-0.6826
```

```{r}
qnorm(0.6826/2, 210, 10*sqrt(3))
```

```{r}
qnorm(1-0.6826/2, 210, 10*sqrt(3))
```

```{r}
qnorm(0.05, 3750,142.302) 
```

```{r}
pnorm(-0.978)

# Rechazamos la hipótesis nula si el p-valor es menor al nivel de significancia


```

```{r}
# Parámetros
x_bar <-14.5        # Media muestral
s <- sqrt(7.84)                # Desviación estándar muestral
n <- 30            # Tamaño de la muestra
alpha <- 0.05                 # Nivel de significancia (1 - nivel de confianza)

# Cálculo de z usando qnorm
z <- qnorm(1 - alpha / 2)     # z = 1.96 para un IC del 95%

# Limites del intervalo de confianza
lower <- x_bar - z * (s / sqrt(n))  # Limite inferior
upper <- x_bar + z * (s / sqrt(n))  # Limite superior

c(lower, upper)

```

```{r}
# Parámetros
n <- 30               # Tamaño de la muestra
S2 <- 7.84                 # Varianza muestral
alpha <- 0.05                    # Nivel de significancia para un IC del 95%

# Valores críticos de Chi-cuadrado
chi2_lower <- qchisq(1 - alpha / 2, df = n - 1)
chi2_upper <- qchisq(alpha / 2, df = n - 1)

# Cálculo del intervalo de confianza para la varianza
lower <- (n - 1) * S2 / chi2_lower
upper <- (n - 1) * S2 / chi2_upper

c(sqrt(lower), sqrt(upper))
```

```{r}
# Parámetros
p_hat <- 9 / 30               # Proporción muestral
n <- 30
alpha <- 0.05

# Cálculo de z usando qnorm
z <- qnorm(1 - alpha / 2)

# Limites del intervalo de confianza
lower <- p_hat - z * sqrt(0.5 * (1 - 0.5) / n)
upper <- p_hat + z * sqrt(0.5 * (1 - 0.5) / n)

c(lower, upper)
```

```{r}
pnorm(18000, 58500-40000, 301.36)
```

```{r}
qnorm(0.95)
```

```{r}
# Definir la ecuación
solve_equation <- function(M) {
  (0 - (72-8*M)) / (sqrt(19.2+1.44*M)) - 1.644854
}

library(rootSolve)

# Ajustar el rango para evitar M = 0
solution <- uniroot(solve_equation, lower = 0, upper = 14420) # Evitar 0
print(solution)

```

```{r}
pnorm(185,200,15) + pnorm(215, 200, 15, lower.tail = F)
```

200 + qnorm(0.025) \* 6.7/sqrt(5)

```{r}
200 + qnorm(0.025) * 6.7/sqrt(5)
```

```{r}

# 200 + qnorm(0.025) * 6.7/sqrt(5)

# Parámetros
mu <- 200  # Media
sigma <- 6.7  # Desviación estándar
n <- 5  # Tamaño de la muestra
alpha <- 0.05  # Nivel de significación

# Desviación estándar del promedio
sigma_prom <- sigma / sqrt(n)

# Valor crítico (z-score para 95% de confianza)
z <- qnorm(1 - alpha / 2)

# Límites del intervalo
L <- mu - z * sigma_prom
U <- mu + z * sigma_prom

# Resultado
L
U

```

```{r}
qnorm(0.01)
```

```{r}
pnorm(1.609)
```

```{r}
# Datos
mu_0 <- 130  # Media poblacional hipotética
sigma <- 1.5 # Desviación estándar poblacional conocida
n <- 9     # Tamaño de muestra
x_bar <- 131.08 # Media muestral
alpha <- 0.01 # Nivel de significancia

# Estadístico z
z <- (x_bar - mu_0) / (sigma / sqrt(n))

# Valor crítico
z_crit <- qnorm(1 - alpha/2)

# p-valor bilateral (ambas colas)
p_valor_bilateral <- 2 * (1 - pnorm(abs(z))) # Considera ambas direcciones (positivo y negativo)

# p-valor unilateral derecha (cola superior)
p_valor_derecha <- 1 - pnorm(z) # Solo considera la cola derecha

# p-valor unilateral izquierda (cola inferior)
p_valor_izquierda <- pnorm(z) # Solo considera la cola izquierda

list(z = z, z_crit = z_crit, p_valor_bilateral = p_valor_bilateral, 
     p_valor_derecha = p_valor_derecha, p_valor_izquierda = p_valor_izquierda)
```

```{r}
# Parámetros del problema
mu <- 130  # Media poblacional según el fabricante
x_bar <- 131.08  # Media muestral
sigma <- 1.5  # Desviación estándar conocida
n <- 9  # Tamaño de la muestra
alpha <- 0.01  # Nivel de significación

# Cálculo del estadístico de prueba (z-score)
z <- (x_bar - mu) / (sigma / sqrt(n))

# Valor crítico para una prueba bilateral
z_crit <- qnorm(1 - alpha / 2)

# Decisión
if (abs(z) > z_crit) {
  decision <- "Rechazar la afirmación del fabricante (rechazar H0)"
} else {
  decision <- "No se rechaza la afirmación del fabricante (no se rechaza H0)"
}

# Resultados
list(
  Estadistico_prueba = z,
  Valor_critico = c(-z_crit, z_crit),
  Decision = decision
)

```

```{r}
pnorm(9.8918, 10, 0.2) + pnorm(10.1032, 10, 0.2, lower.tail = F)
```

```{r}
1 - pnorm(2.58) + pnorm(-2.58)
```

```{r}
# Datos
mu_0 <- 5.6  # Media poblacional hipotética
s <- 0.462     # Desviación estándar muestral
n <- 11     # Tamaño de muestra
x_bar <- 5.845 # Media muestral
alpha <- 0.01 # Nivel de significancia

# Estadístico t
t <- (x_bar - mu_0) / (s / sqrt(n))

# Grados de libertad
df <- n - 1

# Valores críticos
t_crit_bilateral <- qt(1 - alpha / 2, df) # Bilateral
t_crit_izquierda <- qt(alpha, df)        # Unilateral izquierda
t_crit_derecha <- qt(1 - alpha, df)      # Unilateral derecha

# p-valores
p_valor_bilateral <- 2 * (1 - pt(abs(t), df))
p_valor_derecha <- 1 - pt(t, df)
p_valor_izquierda <- pt(t, df)

list(t = t, t_crit_bilateral = t_crit_bilateral, 
     t_crit_izquierda = t_crit_izquierda, t_crit_derecha = t_crit_derecha, 
     p_valor_bilateral = p_valor_bilateral, p_valor_derecha = p_valor_derecha, 
     p_valor_izquierda = p_valor_izquierda)
```

```{r}
# Datos
p_0 <- 0.1     # Proporción poblacional hipotética
p_hat <- 7/100   # Proporción muestral
n <- 100       # Tamaño de muestra
alpha <- 0.05  # Nivel de significancia

# Estadístico z
z <- (p_hat - p_0) / sqrt(p_0 * (1 - p_0) / n)

# Valores críticos
z_crit_bilateral <- qnorm(1 - alpha / 2) # Bilateral
z_crit_izquierda <- qnorm(alpha)        # Unilateral izquierda
z_crit_derecha <- qnorm(1 - alpha)      # Unilateral derecha

# p-valores
p_valor_bilateral <- 2 * (1 - pnorm(abs(z)))
p_valor_derecha <- 1 - pnorm(z)
p_valor_izquierda <- pnorm(z)

list(z = z, z_crit_bilateral = z_crit_bilateral, 
     z_crit_izquierda = z_crit_izquierda, z_crit_derecha = z_crit_derecha, 
     p_valor_bilateral = p_valor_bilateral, p_valor_derecha = p_valor_derecha, 
     p_valor_izquierda = p_valor_izquierda)

# Rechazamos la hipótesis nula si el p-valor es menor al nivel de significancia

```

```{r}
# Datos
p_0 <- 0.3     # Proporción poblacional hipotética
p_hat <- 50/200   # Proporción muestral
n <- 200       # Tamaño de muestra
alpha <- 0.05  # Nivel de significancia

# Estadístico z
z <- (p_hat - p_0) / sqrt(p_0 * (1 - p_0) / n)

# Valores críticos
z_crit_bilateral <- qnorm(1 - alpha / 2) # Bilateral
z_crit_izquierda <- qnorm(alpha)        # Unilateral izquierda
z_crit_derecha <- qnorm(1 - alpha)      # Unilateral derecha

# p-valores
p_valor_bilateral <- 2 * (1 - pnorm(abs(z)))
p_valor_derecha <- 1 - pnorm(z)
p_valor_izquierda <- pnorm(z)

list(z = z, z_crit_bilateral = z_crit_bilateral, 
     z_crit_izquierda = z_crit_izquierda, z_crit_derecha = z_crit_derecha, 
     p_valor_bilateral = p_valor_bilateral, p_valor_derecha = p_valor_derecha, 
     p_valor_izquierda = p_valor_izquierda)
```

```{r}
options(scipen=999)
1 - pnorm(3.794)
```
